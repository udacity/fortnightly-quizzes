# Deep Learning ND101

### Quiz Week 19, 2019

**Q1**: You have two `nupmy` arrays `a` and `b`, both with shape (784,). Which of the following will create a matrix `c` of shape (2,784), with `a` in its first row and `b` in the second row?

1. `c = np.hstack((a,b))`
2. `c = np.vstack(a,b)`
3. `c = np.stack((a,b),0)`
4. `c = np.concatenate((a,b))`

**Answer:3**


**Q2:** Which is/are the right way to transpose the numpy array X:

```
>>> X
array([[ 0.51781407,  0.40376168,  0.02014567,  0.79970514,  0.47814232],
       [ 0.4582631 ,  0.86805083,  0.98025586,  0.62839894,  0.91543721]])

```

1. X.reshape((5,2))
2. X.T
3. X = X.transpoose()
4. X = np.transpose(X)

**Answer: 3,4**


**Q3:** Which of the following is/are valid ways of squaring every elemment of a matrix `M`?

1. `M **= 2`
2. `M .^ 2`
3. `M.dot(M.T)`
4. `M = np.matmul(M,M.T)`

**Answer: 1**


**Q4:** Given `y = W*x`, where `y` has shape (n,1), `x` has shape (m,1) and `W` has shape (n,m), if we want to find x from y, what is the numpy code for doing so?

1. `x  = np.invert(W)*y`
2. `x  = W**-1.0 * y`
3. `x  = 1.0/W * y`
4. `x = numpy.linalg.inv(W)*y`

**Answer:4**

**Q5:** Which is the right way to extract odd rows from a numpy array `A` with shape (500,784)?
1. A[0::1, :]
2. A[::2, :]
3. A[:2:, :]
4. A[1::2, :]

**Answer:4**

### Quiz for Week of Jun 10, 2019

**Q1:** The two-input parity function P(x,y) has two boolean inputs x and y, each of which can either be 0 or 1. The output of P(x,y) is 0 if the number of its inputs that are equal to 1 are even otherwise it's 1. Which of the following is true regarding P?

1. A single perceptron can predict the output of P
2. A perceptron with a hidden layer cannot predict the output of P
3. P is the inverse of the XOR function and its output can be predicted with a multi-layer perceptron just like XOR.
4. P is equivalent to the XOR function and its output can be predicted with the same multi-layer perceptron as XOR.


**Q2:** Suppose you are trying to build a perceptron for mimicking the AND function. The perceptron has two inputs x and y, each of which can either be 0 or 1, the output of the perceptron should be positive only if both x and y are 1s. You, decide to fix the bias at b=-5, and then start searching for appropriate weights w0 and w1 so that w0 * x + w1 * y + b acts as intended. You arbitrarily pick w0 = 1 and w2 = 3. For which inputs, these weights behave properly?

1. (x=0, y=0), (x=0, y=1), (x=1, y=1)
2. (x=0, y=0), (x=0, y=1), (x=1, y=0)
3. (x=0, y=0), (x=1, y=1)
4. (x=1, y=1)

**Answer:2**

**Q3:** Suppose your are trying to predict the height of a child(hc) from the height of its father(hf) and the height of its mother(hm) using the equation hc = w0 * hf + w1 * hm + b. Suppose b = 30cm, when trying to find the right values of w0 and w1, you compare your prediction(hc), with the (known) height and record the absolute difference. Which of the following is false regarding the error function?

1. The error function is the sum of absolute differences for all children
2. The error function is a function of w0, w1
3. The error function is guaranteed to be zero for values of w0 and w1 that predict all heights quite accurately
4. The error function is small for values of w0 and w1 that predict all heights quite accurately, but grows large for bad choices of w0 and w1.

**Answer:3**

**Q4:** When classifying a neighborhood into \[No Income, Low_Income, Medium Income, High Income\], how should the vector \[Low_Income, High_Income, Low_Income, Low_income, Medium Income\] be one-hot encoded?

1. \[100, 001, 100, 100, 010\]
2. \[0100, 0001, 0100, 0100, 0010\]
3. \[000, 001, 000, 000, 010\]
4. \[0000, 0010, 0000, 0000, 0001\]

**Answer:2**

**Q5:** The gradient of a function is g(x) = 1 | x >= 0; 10^-2 x <0, what is the function?
1. Rectified Linear Unit (RELU)
2. Leaky Rectified Linear Unit (Leaky-RELU)
3. Sigmoid
4. log

**Answer:2**

