# Deep Reinforcement Learning Nanodegree (ND893)

### Quiz Week of Jun 10, 2019

**Q1:** If a state S has 4 neighbors A,B,C and D with state values of -1, 1, 0 and 2 respectively, and the rewards for the 
transitions S->A, S->B, S->C and S->D are 1, -1, 1, and 0, what is the state value of S?

1. 0
2. 2
3. 1
4. -1

**Answer:2**

**Q2:** Which is true for state value function?

1. The state value function is positive for all states.
2. The state value of a state is the minimum of the state values of all next states.
3. The state value of the taget state is infinity.
4. The state value of a state can be smaller or larger than the state values of the target states.

**Answer4**

**Q3:** What is the realtionship between the state value, action values of a state and a policy?

1. Given the action values of all states, one can find an optimum policy in a straightforward fashion.
2. One can find the state value function, given only a policy, without any information about the environment.
3. One can find the action value function, given only a policy, without any information about the environment.
4. Given only state values, one can find the corresponding policy.

**Answer:1**

**Q4:** Which of the following is TRUE about a reinforcement learning environment?

1. A realistic environment does not possesses an underlying one-step dynamics
2. The one-step dynamics of an environment cannot be estimated
3. Dynamic programming can be used to find the exact one-step dynamics of any environment.
4. The one-step dynamics is generally estimated by letting an agent interact with an environment.

**Answer:4**


**Q5:** Which of the following is true about a reinforcement learning environment.
1. The reward is a function is a property of the enviroment and does not depend on the agent.
2. The policy learnt by an agent is independent of the environment's one-step dynamics.
3. The one-step dynamics of a stochastic environment changes over time.
4. The optimum policy is never stochastic.

**Answer:4**

